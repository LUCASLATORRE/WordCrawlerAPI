
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Swagger UI</title>
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Source+Code+Pro:300,600|Titillium+Web:400,600,700" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.2.2/swagger-ui.css" >
  <style>
    html
    {
      box-sizing: border-box;
      overflow: -moz-scrollbars-vertical;
      overflow-y: scroll;
    }
    *,
    *:before,
    *:after
    {
      box-sizing: inherit;
    }

    body {
      margin:0;
      background: #fafafa;
    }
  </style>
</head>
<body>

<div id="swagger-ui"></div>

<script src="https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.2.2/swagger-ui-bundle.js"> </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/swagger-ui/3.2.2/swagger-ui-standalone-preset.js"> </script>
<script>
window.onload = function() {

  var spec = {"swagger": "2.0", "info": {"description": "This API will take a url(s), a word, and will count the number of matches (case-sensitive). In other words, this API is responsible for crawling the URL(s) reported and returning a response containing a json with the number of occurrences of the reported word, per site. \n\n  Example:\nhttp://127.0.0.1:5000/?url=www.pyhon.org&url=flask.pocoo.org&url=www.djangoproject.com&word=docs&ignorecase=true\n\n `?url=python.org` is the url to be requested\n\n `&word=docs` is the word to be searched and counted \n\n `&ignorecase=true` pass this argument to match ignoring case \n\n Return JSON: \n\n\n[\n\n &nbsp;&nbsp;&nbsp;&nbsp;{\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"http://www.python.org\": { \n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;        \"docs\": 13\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n\n &nbsp;&nbsp;&nbsp;&nbsp;},\n\n &nbsp;&nbsp;&nbsp;&nbsp;{\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"http://flask.pocoo.org\": {\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"docs\": 10\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n\n &nbsp;&nbsp;&nbsp;&nbsp;},\n\n &nbsp;&nbsp;&nbsp;&nbsp;{\n\n\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"http://www.djangoproject.com\": {\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\"docs\": 16\n\n &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;}\n\n &nbsp;&nbsp;&nbsp;&nbsp;}\n\n\n]\n\n\n=========================================================== \n\n Setup \n\n To run this script, you'll need [Python 3.x](https://www.python.org/downloads/) installed and [pip](https://pip.pypa.io/en/stable/installing/) to get the packages. \n\n Then you must get the extensions [Flask-restful](http://flask-restful-cn.readthedocs.io/en/0.3.5/installation.html) and [requests](http://docs.python-requests.org/en/master/user/install/) \n\n To get then you can simply open a terminal and type:\n\n `pip install flask-restful` and then `pip install requests`\n\n\n## Running\n\n\nTo run the program, `clone` the repository or download `crawler.py`\n\n\nOpen a terminal and go to the folder that contains `crawler.py` \n\n\nType `python crawler.py` and it will run the service under http://127.0.0.1:5000/\n\n\nThen all you need to do is request the service passing the arguments:\n\n\n- via Browser : you can do it on your browser, just type this in the address box = `http://127.0.0.1:5000/?url=globo.com&url=terra.com.br&word=google`\n\n\n- via cURL : open another terminal and type `curl http://127.0.0.1:5000/ -d \"url=gobo.com\" -d \"url=terra.com.br\" -d \"word=google\" -X GET` \n\n\n## Testing\n\n\nThe file `crawler_test.py` is a *test suit* that was created to be used with the library [pytest](https://docs.pytest.org/en/latest/getting-started.html)\n\n \nInstall [pytest](https://docs.pytest.org/en/latest/getting-started.html) by running in your terminal `pip install pytest`\n\n\nThen, on the root folder of this project, run the terminal command `pytest`. It will automatically look for and run tests files (that follow a naming convention)\n\n", "version": "1.0.0", "title": "WordCrawlerAPI", "termsOfService": "", "contact": {"email": "lucaslatorre@gmail.com"}, "license": {"name": "MIT License", "url": "https://opensource.org/licenses/MIT"}}, "host": "127.0.0.1:5000", "basePath": "/", "schemes": ["http"], "paths": {"/": {"get": {"tags": ["crawler"], "summary": "Returns the number of matches of the word in the URL.", "description": "Multiple URLs can be provided by assigning more than one URL as an argument. Example: http://127.0.0.1:5000/?url=globo.com&url=terra.com.br&url=estadao.com.br&word=tecnologia", "operationId": "crawler", "produces": ["application/xml", "application/json"], "parameters": [{"name": "url", "in": "query", "description": "Url to be required for the crawler.", "required": true, "type": "array", "items": {"type": "string", "enum": ["url"], "default": "available"}, "collectionFormat": "multi"}, {"name": "word", "in": "query", "description": "Word to match.", "required": true, "type": "string", "items": {"type": "string", "enum": ["word"], "default": "available"}, "collectionFormat": "multi"}], "responses": {"200": {"description": "successful operation", "schema": {"type": "array", "items": {"$ref": "#"}}}, "400": {"description": "Invalid status value"}}}}}};

  // Build a system
  const ui = SwaggerUIBundle({
    spec: spec,
    dom_id: '#swagger-ui',
    deepLinking: true,
    presets: [
      SwaggerUIBundle.presets.apis,
      SwaggerUIStandalonePreset
    ],
    plugins: [
      SwaggerUIBundle.plugins.DownloadUrl
    ],
    layout: "StandaloneLayout"
  })

  window.ui = ui
}
</script>
</body>

</html>
